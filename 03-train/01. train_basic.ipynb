{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎬 영화 리뷰 데이터로 BERT 모델 감성 분석하도록 훈련 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📂 Load dataset\n",
    "\n",
    "- huggingface `datasets` package \n",
    "  ```\n",
    "    pip install datasets\n",
    "  ```\n",
    "\n",
    "- nsmc dataset\n",
    "  - https://huggingface.co/datasets/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99df62feb62b492f80b2c0a9c9eecbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9356826dd77f436c80613340983211f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac94dba98bf9422cb820d553d6b4cc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850c2e3609a840b595217fbaad8f5395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "nsmc_dataset = load_dataset(\"nsmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'document': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '9976970', 'document': '아 더빙.. 진짜 짜증나네요 목소리', 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# DataSetDict 형태로 데이터 구조 , 내용 살펴보기\n",
    "#####################################################################################\n",
    "\n",
    "# document 는 리뷰 , label 은 리뷰의 긍정/부정 (positive / negative)\n",
    "display(nsmc_dataset['train'].features)\n",
    "\n",
    "# label 의 명칭은 'negative' , 'positive' 인데 여기서는 0, 1 로 표현되어 있음\n",
    "display(nsmc_dataset['train'][0])\n",
    "\n",
    "# label 명에 따른 label id 는 `label` feature 를 str2int 로 확인 \n",
    "display(nsmc_dataset['train'].features['label'].str2int('positive'), \n",
    "        nsmc_dataset['train'].features['label'].str2int('negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1702/2225452072.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  display(nsmc_df.groupby('label').apply(lambda x:len(x)/len(nsmc_df)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.501153\n",
       "1    0.498847\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# 판다스 데이터 프레임으로 변환해서 좀더 세밀히 살펴보기\n",
    "#####################################################################################\n",
    "\n",
    "# pandas 데이터 프레임으로 변환해서 자세히 살펴보기\n",
    "nsmc_df = nsmc_dataset['train'].to_pandas()\n",
    "display(nsmc_df.head())\n",
    "\n",
    "# (⚠️ 주의)분류 문제인 경우 label 불균등을 확인해보는 것이 중요\n",
    "# - 만일 label 이 매우 불균등한 상태라면 over sampling, under sampling 등 적용 필요\n",
    "# - negative 50.1% , positive 49.9%\n",
    "display(nsmc_df.groupby('label').apply(lambda x:len(x)/len(nsmc_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean         35.203353\n",
       "std          29.532097\n",
       "min           0.000000\n",
       "25%          16.000000\n",
       "50%          27.000000\n",
       "75%          42.000000\n",
       "max         146.000000\n",
       "Name: review_length, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문자열 길이 알아보기\n",
    "nsmc_df['review_length'] = nsmc_df['document'].str.len()\n",
    "nsmc_df['review_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📂 preprocess\n",
    "\n",
    "자연어 문제의 기본은 `Tokenization` 으로 매우 중요. 예를 들어, `Tokenization` 의 방식에 따라 의미가 달라짐\n",
    "\n",
    "여기서는 BERT Multilangual Tokenizer 를 그대로 사용할 것 (BERT 모델에 들어 있는 것) \n",
    "\n",
    "`Auto` 붙은 것은 pretrained 모델을 갖고 올 때 그에 맞는 class 를 retrieval 해주는 것일 뿐\n",
    "\n",
    "모델은 https://huggingface.co/google-bert/bert-base-multilingual-cased  이 것 가지고 올 것임\n",
    "\n",
    "※ 한국어 Tokenizer , KoBERT 등 사용하는 것도 괜찮음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ecdcb0ee0f41488e30ae5fb926db2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f2c5c829134784b70f9870adc875cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745d74038894436db1bd40296205b83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c19b42e4874670b1b8f1075c26d2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['청', '##춘', '영화', '##의', '최고', '##봉', '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# 문장 tokenize 해보기\n",
    "# - 한국어만으로 학습된 tokenizer 가 아닌 다국어로 학습된 것임에도 어느정도는 잘 함\n",
    "# - `##` 이 들어가지 않은 것은 단어가 시작되는 부분, 들어간 것은 이전 단어와 이어지는 것\n",
    "#####################################################################################\n",
    "seq = \"청춘 영화의 최고봉.\"\n",
    "\n",
    "tok.tokenize(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'input_ids': [101, 9751, 97707, 42428, 10459, 83491, 118989, 119, 102],\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# input_ids 는 토큰을 vocabulary 에 포함된 토큰이 id 로 매핑한 결과\n",
    "# attention_mask 는 해당 토큰이 실제 데이터인지 여부를 마킹 (패팅 토큰 등은 0)\n",
    "# token_type_ids 는 문장을 구분하는데 사용됨. \n",
    "# - 예를 들어 premise, hypothesis 의 NLI (함의/모순/중립 판단) 하는 경우 두 개의 문장을 서로 구분하는 역할\n",
    "from pprint import pprint\n",
    "pprint(tok(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0, 0]],\n",
      " 'input_ids': [[101, 9751, 97707, 42428, 10459, 83491, 118989, 119, 102],\n",
      "               [101, 9751, 97707, 102, 0, 0, 0, 0, 0]],\n",
      " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# 패딩으로 채워진 두 번째 짧은 문장에서 패팅에 해당 하는 위치는 attention mask 가 0 임\n",
    "seq2 = '청춘'\n",
    "pprint(tok([seq, seq2], padding=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고\n",
    "\n",
    "NLI Task 의 경우 아래 같은 코드를 통해 입력을 모델에게 줌 (예시임. GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff89e1deb8ca4756b9cd2b3a71190139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7876c274c90643a083d30eb47b424855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d0f286c60d44a18f9df33686720b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e8fabf7acb482ebc3444098630bd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "premise = \"The quick brown fox jumps over the lazy dog. It did not stop running.\"\n",
    "hypothesis = \"A fast animal is moving.\"\n",
    "\n",
    "input_text = \"[CLS] \" + premise + \" [SEP] \" + hypothesis + \" [SEP]\"\n",
    "tokenized_output = tokenizer.tokenize(input_text)\n",
    "\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_output)\n",
    "\n",
    "# 🔑 [CLS] , [SEP] 이 포함된 모든 토큰에 대해 `1` 로 설정 \n",
    "attention_mask = [1] * len(input_ids) \n",
    "\n",
    "# 🔑 premise 는 0 , hypothesis 는 1 로 설정 \n",
    "sep_indices = [i for i, token in enumerate(tokenized_output) if token == \"[SEP]\"]\n",
    "token_type_ids = [0 if i <= sep_indices[0] else 1 for i in range(len(tokenized_output))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로딩한 데이터(DataSetDict)의 문장을 최대 32 길이로 하고 짧은 경우 padding 하여 tokenize \n",
    "def tokenizer(data):\n",
    "    return tok(data['document'], max_length=32, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3261c2ca5114b348b73d784fbd39815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cad4d29a3214c83bff5ad56864a6f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nsmc_dataset_toeknized = nsmc_dataset.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'document': '아 더빙.. 진짜 짜증나네요 목소리',\n",
      " 'id': '9976970',\n",
      " 'input_ids': [101,\n",
      "               9519,\n",
      "               9074,\n",
      "               119005,\n",
      "               119,\n",
      "               119,\n",
      "               9708,\n",
      "               119235,\n",
      "               9715,\n",
      "               119230,\n",
      "               16439,\n",
      "               77884,\n",
      "               48549,\n",
      "               9284,\n",
      "               22333,\n",
      "               12692,\n",
      "               102],\n",
      " 'label': 0,\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "pprint(nsmc_dataset_toeknized['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔄 load model for finetuing\n",
    "\n",
    "`bart-base` 모델을 기반으로 각 task 별로 적절한 layer 를 덧붙이는 것이 필요함. \n",
    "\n",
    "예를 들면, 문장 분류 작업을 위해서는 dense layer 와 softmax 를 붙여서 사용을 해야 하고, \n",
    "\n",
    "질의 응답 같은 경우는 base 모델이 출력하는 토큰 중에서 어디서 부터 어디까지가 답변인지를 식별하는 layer 를 붙여두어야 함\n",
    "\n",
    "transformer 패키지는 각각에 대해서 사전 정의된 layer 를 붙여서 모델을 로딩하도록 할 수 있도록 하고 있고\n",
    "\n",
    "`BertQuestionAnswering`, `BertSequenceClassification` 등의 클래스가 이에 해당함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# device 정의\n",
    "# \n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea753e40e7764e92b09e8f5cf0e7dd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# task 에 적합하도록 layer 를 붙여서 model 로딩\n",
    "#\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "mdoel = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
