{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎬 영화 리뷰 데이터로 BERT 모델 감성 분석하도록 훈련 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📂 Load dataset\n",
    "\n",
    "- huggingface `datasets` package \n",
    "  ```\n",
    "    pip install datasets\n",
    "  ```\n",
    "\n",
    "- nsmc dataset\n",
    "  - https://huggingface.co/datasets/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99df62feb62b492f80b2c0a9c9eecbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9356826dd77f436c80613340983211f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac94dba98bf9422cb820d553d6b4cc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850c2e3609a840b595217fbaad8f5395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "nsmc_dataset = load_dataset(\"nsmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'document': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '9976970', 'document': '아 더빙.. 진짜 짜증나네요 목소리', 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# DataSetDict 형태로 데이터 구조 , 내용 살펴보기\n",
    "#####################################################################################\n",
    "\n",
    "# document 는 리뷰 , label 은 리뷰의 긍정/부정 (positive / negative)\n",
    "display(nsmc_dataset['train'].features)\n",
    "\n",
    "# label 의 명칭은 'negative' , 'positive' 인데 여기서는 0, 1 로 표현되어 있음\n",
    "display(nsmc_dataset['train'][0])\n",
    "\n",
    "# label 명에 따른 label id 는 `label` feature 를 str2int 로 확인 \n",
    "display(nsmc_dataset['train'].features['label'].str2int('positive'), \n",
    "        nsmc_dataset['train'].features['label'].str2int('negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1702/2225452072.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  display(nsmc_df.groupby('label').apply(lambda x:len(x)/len(nsmc_df)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.501153\n",
       "1    0.498847\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# 판다스 데이터 프레임으로 변환해서 좀더 세밀히 살펴보기\n",
    "#####################################################################################\n",
    "\n",
    "# pandas 데이터 프레임으로 변환해서 자세히 살펴보기\n",
    "nsmc_df = nsmc_dataset['train'].to_pandas()\n",
    "display(nsmc_df.head())\n",
    "\n",
    "# (⚠️ 주의)분류 문제인 경우 label 불균등을 확인해보는 것이 중요\n",
    "# - 만일 label 이 매우 불균등한 상태라면 over sampling, under sampling 등 적용 필요\n",
    "# - negative 50.1% , positive 49.9%\n",
    "display(nsmc_df.groupby('label').apply(lambda x:len(x)/len(nsmc_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean         35.203353\n",
       "std          29.532097\n",
       "min           0.000000\n",
       "25%          16.000000\n",
       "50%          27.000000\n",
       "75%          42.000000\n",
       "max         146.000000\n",
       "Name: review_length, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문자열 길이 알아보기\n",
    "nsmc_df['review_length'] = nsmc_df['document'].str.len()\n",
    "nsmc_df['review_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📂 preprocess\n",
    "\n",
    "자연어 문제의 기본은 `Tokenization` 으로 매우 중요. 예를 들어, `Tokenization` 의 방식에 따라 의미가 달라짐\n",
    "\n",
    "여기서는 BERT Multilangual Tokenizer 를 그대로 사용할 것 (BERT 모델에 들어 있는 것) \n",
    "\n",
    "`Auto` 붙은 것은 pretrained 모델을 갖고 올 때 그에 맞는 class 를 retrieval 해주는 것일 뿐\n",
    "\n",
    "모델은 https://huggingface.co/google-bert/bert-base-multilingual-cased  이 것 가지고 올 것임\n",
    "\n",
    "※ 한국어 Tokenizer , KoBERT 등 사용하는 것도 괜찮음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ecdcb0ee0f41488e30ae5fb926db2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f2c5c829134784b70f9870adc875cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745d74038894436db1bd40296205b83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c19b42e4874670b1b8f1075c26d2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['청', '##춘', '영화', '##의', '최고', '##봉', '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# 문장 tokenize 해보기\n",
    "# - 한국어만으로 학습된 tokenizer 가 아닌 다국어로 학습된 것임에도 어느정도는 잘 함\n",
    "# - `##` 이 들어가지 않은 것은 단어가 시작되는 부분, 들어간 것은 이전 단어와 이어지는 것\n",
    "#####################################################################################\n",
    "seq = \"청춘 영화의 최고봉.\"\n",
    "\n",
    "tok.tokenize(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'input_ids': [101, 9751, 97707, 42428, 10459, 83491, 118989, 119, 102],\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# input_ids 는 토큰을 vocabulary 에 포함된 토큰이 id 로 매핑한 결과\n",
    "# attention_mask 는 해당 토큰이 실제 데이터인지 여부를 마킹 (패팅 토큰 등은 0)\n",
    "# token_type_ids 는 문장을 구분하는데 사용됨. \n",
    "# - 예를 들어 premise, hypothesis 의 NLI (함의/모순/중립 판단) 하는 경우 두 개의 문장을 서로 구분하는 역할\n",
    "from pprint import pprint\n",
    "pprint(tok(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0, 0]],\n",
      " 'input_ids': [[101, 9751, 97707, 42428, 10459, 83491, 118989, 119, 102],\n",
      "               [101, 9751, 97707, 102, 0, 0, 0, 0, 0]],\n",
      " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# 패딩으로 채워진 두 번째 짧은 문장에서 패팅에 해당 하는 위치는 attention mask 가 0 임\n",
    "seq2 = '청춘'\n",
    "pprint(tok([seq, seq2], padding=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고\n",
    "\n",
    "NLI Task 의 경우 아래 같은 코드를 통해 입력을 모델에게 줌 (예시임. GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff89e1deb8ca4756b9cd2b3a71190139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7876c274c90643a083d30eb47b424855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d0f286c60d44a18f9df33686720b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e8fabf7acb482ebc3444098630bd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "premise = \"The quick brown fox jumps over the lazy dog. It did not stop running.\"\n",
    "hypothesis = \"A fast animal is moving.\"\n",
    "\n",
    "input_text = \"[CLS] \" + premise + \" [SEP] \" + hypothesis + \" [SEP]\"\n",
    "tokenized_output = tokenizer.tokenize(input_text)\n",
    "\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_output)\n",
    "\n",
    "# 🔑 [CLS] , [SEP] 이 포함된 모든 토큰에 대해 `1` 로 설정 \n",
    "attention_mask = [1] * len(input_ids) \n",
    "\n",
    "# 🔑 premise 는 0 , hypothesis 는 1 로 설정 \n",
    "sep_indices = [i for i, token in enumerate(tokenized_output) if token == \"[SEP]\"]\n",
    "token_type_ids = [0 if i <= sep_indices[0] else 1 for i in range(len(tokenized_output))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
